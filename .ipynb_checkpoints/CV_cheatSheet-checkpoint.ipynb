{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369ceb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23788d-724f-4c9d-ac5e-679a0984c093",
   "metadata": {},
   "source": [
    "## CV Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d9559-9abc-47d6-8375-92cbf099e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(img_path) # reads img in BGR format\n",
    "cv2.imread(img_path,0) # reads img in grey format\n",
    "cv2.imshow('window_name', img) # displays img in the window\n",
    "cv2.imshow('window_name', np.hstack((img1,img2,img3)) # displays multiple img in the window\n",
    "cv2.waitKey(0) # 0, waits indefinetly for the keystroke to close display window\n",
    "cv2.imwrite('img_name', img) # saves img eg save_img.jpg\n",
    "cv2.resize(img, dimension, interpolation = interpolation_method) # resize img, dimension in int\n",
    "cv2.warpAffine(img, M, (cols, rows)) # method for img transformation, dsize=(cols-img_width, rows-img_height) dsize: size of the output image, M-transformation matrix\n",
    "cv2.getRotationMatrix2D(center, angle, scale) # returns Transformation Matrix M, center of rotation, scale = 1 if op_img = ip_img\n",
    "cv2.medianBlur(img,filter_size) # To remove random noise, filter_size is square matrix if filter_size = 5 = (5x5)\n",
    "cv2.filter2D(src=image, ddepth=-1, kernel=kernel1) # for creating filters like smoothing, blurring, sharpening and edge detection in an image, ddepth=-1 depth of o/p same as i/p img\n",
    "cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # convert color to gray img\n",
    "cv2.GaussianBlur(img,(5,5),sigma) # sigma - Gaussian Standard Deviation\n",
    "cv2.medianBlur(img,ksize) #ksize - kernal size it must be odd and greater than 1\n",
    "abs_grad_x = cv2.convertScaleAbs(grad_x) # gradient of img in x direction\n",
    "abs_grad_y = cv2.convertScaleAbs(grad_y) # gradient of img in y direction\n",
    "magnitude = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0) # Blends images, magnitude - sobel gradient magnitude\n",
    "cv2.Laplacian(src_gray, ddepth, ksize=3) # ksize should be odd          \n",
    "cv2.HoughLinesP(Canny_img, 1, np.pi / 180, 50, None, 50, 10) # returns list of lines in canny img based on parameters passed\n",
    "cv2.fillpoly(Image,End_Points,Color) # End_Points: Points of polygon(triangle 3 end points, rectangle 4 end points), color - of a polygon eg Blue (255,0,0)\n",
    "cv2.line(image, start_point, end_point, color, thickness) # start_point - (x1,y1), end_point (x2,y2)\n",
    "cv2.bitwise_and(src_img, mask_img)\n",
    "edge = cv2.Canny(img, t_lower, t_upper) # t_lower, t_upper lower and upper thresholds\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15) # initiate stereo object to find disparity map\n",
    "sift = cv2.xfeatures2d.SIFT_create() #initialize SIFT detector&descriptor\n",
    "kp, des = sift.detectAndCompute(gray,None) # compute keypoint and descriptors\n",
    "matcher = cv2.DescriptorMatcher_create(\"BruteForce\") #Initiate match object\n",
    "matches = match_method.knnMatch(query_des,train_des, k=2) # strogest 2 matches for each query\n",
    "cv2.warpPerspective(img,transformMartix,(maxWidth, maxHeight),flags=cv2.INTER_LINEAR) #Perspective transform\n",
    "# compute the disparity map\n",
    "disparity = stereo.compute(imgL,imgR) # disparity map of left img and right img gives depth of img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901dda3-20b2-46b3-9b3c-d0d56bc69cc7",
   "metadata": {},
   "source": [
    "## NumPy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8a047-2f84-41db-badf-366a357c6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = img.shape # numpy method returns height width and color channel of the img\n",
    "# find center of img\n",
    "height, width = img.shape[:2] \n",
    "center = (width/2, height/2)\n",
    "# function is used to Clip (limit) the values in an array\n",
    "np.clip(height_dim, a_min=0, a_max=img.shape[0], out=none) # height_dim - img height to clip, a_min - min value to clip, a_max - max value to clip, out -copies clipped array\n",
    "img(height_dim[0]:height_dim[1],width_dim[0]:width_dim[1]) #crops image\n",
    "np.ones(matrix_dimension,dtype=np.32) # create unit matrix of matrix_dimension = (r,c) and dtype=np.float32\n",
    "np.zeros(matrix_dimension,dtype=np.32) # create unit matrix of matrix_dimension = (r,c) and dtype=np.float32\n",
    "mask = np.zeros_like(img) # creates matrix with dimension same as img\n",
    "np.rad2deg() #converts rad to degrees\n",
    "np.arctan2(gradx,grady) #returns in rad\n",
    "cpy_img = np.copy(img) # copies image\n",
    "np.polyfit(x,y,degree) # returns the coefficient of polynomials Eg for line returns slope(m) & intercept(c). degree = 1\n",
    "np.average(array,axis=0) # averages n-dim array along the axis (0-col, 1-row)\n",
    "np.random.randint(0, 255, (100, 3)) #start:0, end:255,100 No.Of 3 random val between start and end\n",
    "np_array.reshape(-1, 1, 2) # reshape to (1,2) dim matrix of n matrix (-1 means, max matrix possible)\n",
    "# Sobel filters\n",
    "np.array([[-1,0,1], [-2,0,2], [-1,0,1]]) # Sobel vertical filter\n",
    "np.array([[-1,-2,-1], [0,0,0], [1,2,1]]) # Sobel Horizontal filter, transpose of vertical filter\n",
    "# prewitt filters\n",
    "np.array([[-1,0,1], [-1,0,1], [-1,0,1]]) # prewitt vertical filter\n",
    "np.array([[-1,-1,-1], [0,0,0], [1,1,1]]) # prewitt Horizontal filter, transpose of vertical filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bf23c-3297-47d0-bc2e-50a4e1e3ab57",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Important Notes\n",
    "- interpolation_method = [cv2.INTER_AREA, cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]\n",
    "- OpenCV reads image in BGR format not in RGB, but writes in RGB format\n",
    "\n",
    "## Kernal\n",
    "- A simple 2d matrix used in convolution or Convolution Matrix or a mask used to ***blur, sharpen and edge detect an image***.\n",
    "- *Convolution* - Dot product between filter and Image\n",
    "\n",
    "![Kernal](docs/Typesofkernels.png)\n",
    "\n",
    "## Filters\n",
    "- LPF (Low Pass Filter) helps in removing noise, blurring images, etc. \n",
    "- HPF (High Pass Filter) filters help in *finding edges* in images\n",
    "- **Image Blur**\n",
    "    - Also called image smoothing, removes high frequency content (noise, edges) from the image.\n",
    "    - Edges are blurred little bit in the operation\n",
    "- **LPF Types**\n",
    "    - Averaging - cv2.blur()\n",
    "    - Gaussian Blurring\n",
    "    - Median Blurring - For impulse/random noise Eg. salt and pepper noise\n",
    "    - Bilateral Blurring\n",
    "    \n",
    "## Edge Detection\n",
    "- LPF + Image Gradient\n",
    "- Edge is nothing but sharp change in pixel intensity of image\n",
    "- **Types**\n",
    "    1. *Sobel/Perwitt Filter* - Applies 1st order of derivative (Edge Detection in 2 steps, horizontal and vertical) to find edge\n",
    "        1. Apply Gaussian Blur for Noise reduction (LPF)\n",
    "        2. Find gradient of x and y\n",
    "        3. Find the magnitude\n",
    "    2. *Laplace operator* - Applies 2nd order of derviative (Edge Detection in 1 steps, horizontal and vertical combined) to find edge\n",
    "        1. Apply Gaussian Blur for Noise reduction (LPF)\n",
    "        2. Apply Laplace filter\n",
    "    3. *Canny Edge Detector*\n",
    "        1. Apply Gaussian Blur for Noise reduction (LPF)\n",
    "        2. Find gradient of x and y\n",
    "        3. Fnid the magnitude and direction\n",
    "            1. Direction gives the angle value of the edges in the image\n",
    "        4. Find Non-maximum suppression\n",
    "            - Retain max intensity pixels (255-white) compared to threshold\n",
    "            1. Create a matrix initialized to 0 of the same size of the original gradient intensity matrix;\n",
    "            2. Identify the edge direction based on the angle value from the angle matrix;\n",
    "            3. Check if the pixel in the same direction has a higher intensity than the pixel that is currently processed;\n",
    "            4. Return the image processed with the non-max suppression algorithm.\n",
    "        5. Hysteresis Edge tracking\n",
    "        \n",
    "## Transform\n",
    "- Change of position and orientation of a frame wrt another frame\n",
    "- Frames - coordinates attached to the body\n",
    "- Transform = Translation + Rotation\n",
    "- **Hough Transform**\n",
    "    - detects any shape, if that shape can be represented in mathematical form. It can detect the shape even if it is broken or distorted a little bit. \n",
    "    - **Hough Line Transform**\n",
    "        - A line can be represented as y = mx + c (cartesian cordinate ) or in polar coordinate as r = xcosθ + ysinθ (parametric/Hough form) where r is the perpendicular    distance from origin to the line, and θ is the angle formed by this perpendicular line.\n",
    "        - ***cv2.HoughLinesP(Canny_img, 1, np.pi / 180, 50, None, 50, 10)***\n",
    "            - Canny_img: Output of the edge detector. It should be a grayscale image (although in fact it is a binary one)\n",
    "            - lines: A vector that will store the parameters (xstart,ystart,xend,yend) of the detected lines\n",
    "            - rho : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "            - theta: The resolution of the parameter θ in radians. We use 1 degree (CV_PI/180)\n",
    "            - threshold: The minimum number of intersections to \"*detect*\" a line\n",
    "            - minLineLength: The minimum number of points in pixel that can form a line. Lines with less than this number of points are disregarded.\n",
    "            - maxLineGap: The maximum gap between two points in pixel to be considered in the same line\n",
    " \n",
    " ## Lane detection\n",
    "     - **Steps Involved**\n",
    "         1. Noise filtering(img)-> (filter_img)\n",
    "         2. Edge deection (filter_img) -> canny edge detector (canny_img)\n",
    "         3. Find ROI (canny_img) -> roi_img\n",
    "         4. Hough line transform (roi_img) -> list_lines\n",
    "         5. Find average slope and intercept for Hough lines -> avg (m,c)\n",
    "         6. find line with equ using m and c -> avg_line (left, right)\n",
    "         7. Display line (avg_line)\n",
    "             - Merge image (img, masked_imgOfLines-avg_line)\n",
    "\n",
    " ## Feature Detection, Description and Matching\n",
    "     - Feature in an image is nothing but the keypoint/region of interest\n",
    "     - Feature matching has an interesting applications like image stitching/panaroma\n",
    "     - The input images are called\n",
    "         1. query image\n",
    "         2. train image\n",
    " \n",
    "     Match object has following attributes:\n",
    "\n",
    "        Match.distance - Distance between descriptors. The lower, the better it is.\n",
    "        Match.trainIdx - Index of the descriptor in train descriptors\n",
    "        Match.queryIdx - Index of the descriptor in query descriptors\n",
    "        Match.imgIdx - Index of the train image.\n",
    "    - **Perspective Transform**\n",
    "        Associated with the change in the viewpoint. This type of transformation does not preserve parallelism,               length, and angle. But they do preserve collinearity and incidence. This means that the straight lines will           remain straight even after the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d221fab-665b-43f2-8a6b-8ebcb20b2248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
